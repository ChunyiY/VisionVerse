ERA_MAPPING = {
    "Prehistoric Cave Art": "primitive cave drawings, earthy tones, animal figures, charcoal style",
    "Mesopotamian Art": "cuneiform, stone reliefs, profile figures, ancient mythology",
    "Ancient Egyptian Art": "hieroglyphs, profile figures, flat perspective, gods and pharaohs",
    "Aegean Art": "frescoes, marine motifs, spiral patterns, Bronze Age style",
    "Ancient Greek Art": "idealized human forms, marble statues, classical harmony",
    "Ancient Roman Art": "realistic portraits, arches and columns, mosaics",
    "Byzantine Art": "gold backgrounds, religious icons, flat faces, spiritual themes",
    "Romanesque": "rounded arches, religious frescoes, thick lines, medieval colors",
    "Gothic Art": "pointed arches, stained glass, illuminated manuscripts, dramatic expression",
    "Islamic Art": "arabesque patterns, geometric design, calligraphy, no human figures",
    "Classical Indian Art": "sculptural elegance, Hindu deities, fluid movement",
    "Han Dynasty Art": "bronze casting, jade ornaments, Confucian symbolism",
    "Tang Dynasty Art": "courtly elegance, Buddhist imagery, vibrant colors",
    "Song Dynasty Landscape Painting": "monochrome ink wash, naturalism, mountains and rivers",
    "Ukiyo-e": "woodblock print, flat color, outlines, Edo period",
    "Mughal Miniature Painting": "intricate detail, royal scenes, Persian influence",
    "Early Renaissance": "perspective, soft realism, biblical scenes, tempera",
    "High Renaissance": "balanced composition, ideal forms, divine themes",
    "Northern Renaissance": "oil painting, detailed textures, domestic scenes",
    "Mannerism": "elongated forms, complex poses, vibrant color",
    "Baroque": "dramatic lighting, intense emotion, ornate detail",
    "Rococo": "pastel colors, playful themes, flowing curves",
    "Dutch Golden Age": "realistic still life, merchant portraits, indoor scenes",
    "Neoclassicism": "heroic themes, Greek and Roman revival, symmetry",
    "Romanticism": "emotional landscapes, heroic rebellion, stormy skies",
    "Academic Art": "polished finish, historical scenes, strict realism",
    "Realism": "everyday life, accurate detail, working-class subjects",
    "Impressionism": "visible brushstrokes, natural light, fleeting moments",
    "Post-Impressionism": "bold color, symbolic content, structured form",
    "Pointillism": "dot technique, optical mixing, Seurat style",
    "Symbolism": "dream imagery, mythic subjects, inner meaning",
    "Art Nouveau": "organic curves, floral motifs, decorative elegance",
    "Arts and Crafts Movement": "handcrafted aesthetic, medieval revival, functional design",
    "Nabis": "flat planes, spiritual symbolism, post-impressionist style",
    "Expressionism": "bold color, emotional distortion, inner angst",
    "Fauvism": "wild brushstrokes, vibrant colors, simplified forms",
    "Cubism": "fragmented forms, multiple perspectives, muted palette",
    "Futurism": "dynamic motion, urban energy, mechanized forms",
    "Orphism": "colorful abstraction, circular forms, musical harmony",
    "Suprematism": "geometric abstraction, spiritual purity, Malevich",
    "Constructivism": "industrial materials, abstract structure, propaganda",
    "De Stijl": "primary colors, grid structure, minimal composition",
    "Dada": "absurd collage, anti-art, protest themes",
    "Neue Sachlichkeit": "sharp realism, social critique, Weimar style",
    "Surrealism": "dreamlike, irrational juxtapositions, subconscious imagery",
    "Magic Realism": "realistic setting, fantastical twist, muted palette",
    "Bauhaus": "functional minimalism, geometry, industrial design",
    "Abstract Expressionism": "gestural brushstrokes, raw emotion, large canvases",
    "Color Field Painting": "broad color areas, contemplative tone, Rothko",
    "CoBrA": "childlike spontaneity, vibrant chaos, expressive form",
    "Pop Art": "comic style, consumer icons, bright flat color",
    "Op Art": "optical illusions, geometric patterns, black-and-white",
    "Minimalism": "geometric reduction, repetition, less is more",
    "Conceptual Art": "idea over form, textual elements, anti-commercial",
    "Photorealism": "extreme detail, camera-like clarity, urban scenes",
    "Land Art": "earth materials, large scale, site-specific",
    "Installation Art": "immersive, spatial arrangement, conceptual environment",
    "Performance Art": "live action, ephemeral, bodily expression",
    "Feminist Art": "gender critique, body themes, personal narrative",
    "Postmodern Art": "irony, appropriation, cultural remix",
    "Graffiti Art": "urban mural, spray paint, bold lines",
    "Street Art": "public space, visual activism, stencil style",
    "Neo-Expressionism": "bold gestures, raw emotion, personal iconography",
    "Transavantgarde": "revival of painting, symbolic expression, postmodern",
    "Lowbrow Art": "pop culture, comic surrealism, underground aesthetic",
    "Digital Art": "pixel-based, algorithmic form, cyber motifs",
    "Generative Art": "code-driven visuals, algorithmic design, randomness",
    "Net Art": "internet-based, glitch, hyperlinks",
    "New Media Art": "interactive tech, screen-based, immersive",
    "AI Art": "machine-generated, neural aesthetics, latent space",
    "Glitch Art": "data corruption, pixel noise, digital decay",
    "Cyberpunk Aesthetic": "neon dystopia, chrome tech, urban decay",
    "Vaporwave": "retro 90s, greek statues, pink and cyan, lo-fi",
    "Afrofuturism": "African culture meets sci-fi, space themes, tribal tech",
    "Kitsch Art": "tacky beauty, over-sentimentality, pop excess",
    "Na√Øve Art": "childlike perspective, simple color, sincere form",
    "Outsider Art": "untrained artist, raw creativity, outsider vision",
    "Hyperrealism": "ultra-detailed, photographic precision, surreal clarity",
    "Contemporary Indigenous Art": "native symbols, ancestral stories, cultural preservation",
    "Post-Internet Art": "online culture, meme remix, social media commentary",
    "Bio Art": "living materials, DNA imagery, biotech critique",
    "Relational Aesthetics": "social interaction, community-focused, collaborative",
    "Social Practice Art": "activism, public participation, process over product",
    "Data Art": "data visualization aesthetics, generative graphics",
    "Augmented Reality Art": "interactive overlay, 3D virtual blend, mobile-based",
    "Virtual Reality Art": "immersive digital space, viewer agency, simulation",
    "NFT Art": "crypto-backed, unique ownership, blockchain aesthetic",
    "Eco Art": "nature integration, sustainability, environmental message",
    "Sustainable Design": "eco-conscious, low-impact, ethical materials",
    "Speculative Design": "future scenarios, critical objects, design fiction",
    "Metamodernism": "hopeful oscillation, sincerity with irony, poetic structure",
    "Zine Culture Aesthetics": "DIY collage, typewriter fonts, punk graphics",
    "Collage Art": "cut-and-paste, fragmented visuals, mixed media",
    "Assemblage": "3D collage, found objects, sculptural composition",
    "Comic Book Art Style": "line art, dynamic panels, speech bubbles",
    "Manga Style": "black and white, expressive faces, Japanese composition",
    "Anime Style": "cel shading, colorful characters, cinematic perspective",
    "Video Game Concept Art": "fantasy environments, character design, digital painting",
    "3D Modeling Art": "rendered models, photoreal textures, virtual lighting",
    "AI-Generated Prompt Art": "latent fusion, abstract logic, neural inspiration",
    "AI-Style Transfer Art": "deep neural brushstrokes, mixed artist mimicry"
}




import torch
from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
import cv2
import random
import subprocess
import json
import time
from diffusers import StableDiffusionPipeline
from transformers import CLIPTokenizer, CLIPTextModel
from torch.nn.functional import cosine_similarity

import os

# Optional: Use HuggingFace mirror for regions with access restrictions
# Uncomment the line below if you need to use a mirror
# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ====== Configuration ======
# Get the project root directory (parent of src/)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
WORD_BANK_PATH = os.path.join(BASE_DIR, 'data', 'random_words.txt')
IMAGE_SAVE_PATH = os.path.join(BASE_DIR, 'captured.jpg')
ART_STYLE_PATH = os.path.join(BASE_DIR, 'data', 'art_style.txt')
OLLAMA_MODEL = "mistral"
OUTPUT_DIR = os.path.join(BASE_DIR, 'output')

clip_tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch32")
clip_text_model = CLIPTextModel.from_pretrained("openai/clip-vit-base-patch32")

# Initialize global variables
word_bank, art_styles = [], []
pipe = None  # Stable Diffusion pipeline

def init_resources():
    """Initialize word bank, art style list, and Stable Diffusion model"""
    global word_bank, art_styles, pipe
    
    # Ensure output directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Load word bank
    try:
        with open(WORD_BANK_PATH, 'r', encoding='utf-8-sig') as f:
            word_bank = [line.strip() for line in f if line.strip()] or ["poetry", "dream", "light", "shadow"]
        print(f"Loaded {len(word_bank)} words")
    except Exception as e:
        print(f"Failed to load word bank: {e}")
        word_bank = ["poetry", "dream", "light", "shadow"]

    # Load art styles
    try:
        with open(ART_STYLE_PATH, 'r', encoding='utf-8-sig') as f:
            art_styles = [line.strip() for line in f if line.strip()] or ["impressionism", "surrealism", "ukiyo-e", "digital art"]
        print(f"Loaded {len(art_styles)} art styles")
    except Exception as e:
        print(f"Failed to load art styles: {e}")
        art_styles = ["impressionism", "surrealism", "ukiyo-e", "digital art"]
    
    # Initialize Stable Diffusion pipeline
    try:
        print("Loading Stable Diffusion model...")
        device = "mps" if torch.backends.mps.is_available() else ("cuda" if torch.cuda.is_available() else "cpu")
        torch_dtype = torch.float32
        
        pipe = StableDiffusionPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            torch_dtype=torch_dtype
        ).to(device)
        
        pipe.enable_attention_slicing()
        print("Stable Diffusion model loaded successfully")
    except Exception as e:
        print(f"Failed to load Stable Diffusion model: {e}")
        raise

def capture_image(save_path=IMAGE_SAVE_PATH):
    """Capture photo from camera and save"""
    for cam_id in range(3):
        cap = cv2.VideoCapture(cam_id)
        if cap.isOpened():
            ret, frame = cap.read()
            cap.release()
            if ret:
                cv2.imwrite(save_path, frame)
                print(f"Image saved: {save_path} (camera {cam_id})")
                return save_path
    raise RuntimeError("Failed to capture image")

def generate_blip_prompt(image_path):
    """Generate image caption using BLIP"""
    try:
        device = "cuda" if torch.cuda.is_available() else ("mps" if torch.backends.mps.is_available() else "cpu")
        processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
        model = BlipForConditionalGeneration.from_pretrained(
            "Salesforce/blip-image-captioning-base",
            use_safetensors=True
        ).to(device)

        image = Image.open(image_path).convert("RGB")
        inputs = processor(image, return_tensors="pt").to(device)
        out = model.generate(**inputs, max_new_tokens=50)
        return processor.decode(out[0], skip_special_tokens=True)
    except Exception as e:
        print(f"Failed to generate caption: {e}")
        return "a poetic scene"

def encode_text(texts):
    """Encode text to vectors"""
    inputs = clip_tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = clip_text_model(**inputs)
        return outputs.last_hidden_state[:, 0, :]  # [CLS] token

def get_semantic_words(caption, word_bank, k=4):
    """Select k most semantically relevant words from word bank"""
    if not word_bank:
        return []

    k = min(k, len(word_bank))
    caption_vec = encode_text([caption])  # [1, 512]
    word_vecs = encode_text(word_bank)    # [N, 512]
    similarities = cosine_similarity(word_vecs, caption_vec.repeat(word_vecs.size(0), 1), dim=1)
    top_indices = torch.topk(similarities, k).indices
    return [word_bank[i] for i in top_indices]

def compose_poetry_instruction(caption, keywords):
    """Compose poetry generation instruction"""
    prompt = f"""Write an English poem based on:
Scene: {caption}
Keywords: {', '.join(keywords)}

Requirements:
1. Include all keywords naturally
2. 8-12 lines with rhythm
3. Add a creative title"""
    print("\nPoetry prompt:\n" + prompt)
    return prompt

def generate_with_ollama(model, prompt, timeout=120):
    """Generic Ollama generation function"""
    try:
        result = subprocess.run(
            ["ollama", "run", model, prompt],
            capture_output=True,
            text=True,
            timeout=timeout
        )
        return result.stdout.strip() if result.returncode == 0 else None
    except Exception as e:
        print(f"Failed to generate with {model}: {e}")
        return None

def add_word_to_bank():
    """Manually add a new word to the word bank"""
    new_word = input("Enter a new word to add to the word bank (press Enter to skip): ").strip()
    if new_word:
        with open(WORD_BANK_PATH, 'a', encoding='utf-8') as f:
            f.write(f"\n{new_word}")
        word_bank.append(new_word)
        print(f"New word '{new_word}' added to word bank")


def poem_to_diffusion_prompt(poem):
    selected_style = random.choice(art_styles)
    style_prompt = ERA_MAPPING.get(selected_style, "")
    
    prompt = f"""
    {selected_style} style, {style_prompt},
    High quality, intricate details,
    Scene: {poem.split('.')[0]}
    ---
    Requirements:
    1. Strictly follow {selected_style} artistic characteristics
    2. Maintain poetic atmosphere
    3. Include all key elements from the poem
    """
    
    print(f"\nFinal prompt (enforcing {selected_style} style):\n{prompt}")
    return prompt.strip()


def conservative_fallback(poem, selected_style, era=None):
    """Conservative fallback: manually replace common anachronisms"""
    replacements = {
        "phone": "messenger pigeon",
        "car": "horse carriage", 
        "computer": "astrolabe",
        "neon": "oil lamp",
        "airplane": "flying dragon" if "medieval" in str(era) else "hot air balloon"
    }
    
    adapted_poem = poem
    for modern, historical in replacements.items():
        adapted_poem = adapted_poem.replace(modern, historical)
    
    return f"{selected_style} style painting depicting: {adapted_poem.split('.')[0]}"

def generate_sd_image(prompt):
    """Generate image using Stable Diffusion"""
    if pipe is None:
        raise RuntimeError("Stable Diffusion pipeline not initialized")
    
    timestamp = int(time.time())
    output_path = os.path.join(OUTPUT_DIR, f"art_{timestamp}.png")
    
    print(f"\nGenerating image with Stable Diffusion...")
    print(f"Prompt: {prompt}")
    
    try:
        image = pipe(
                prompt,
                num_inference_steps=40,
                guidance_scale=8.5,
                height=768,
                width=768,
                seed=42
            ).images[0]
        image.save(output_path)
        print(f"Image saved: {output_path}")
        return output_path
    except Exception as e:
        print(f"Failed to generate image: {e}")
        return None

def save_results(image_path, caption, keywords, poem, sd_prompt, art_path=None):
    """Save all results to file (with timestamp)"""
    import datetime
    
    # Ensure output directory exists
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # Create timestamped filename
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"ai_art_prompt_{timestamp}.txt"
    output_path = os.path.join(OUTPUT_DIR, filename)
    
    # Write content
    with open(output_path, "w", encoding='utf-8') as f:
        f.write(f"=== Generation Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n\n")
        f.write(f"Original Image: {image_path}\n")
        f.write(f"Image Caption: {caption}\n")
        f.write(f"Keywords: {', '.join(keywords)}\n\n")
        f.write(f"Poem:\n{poem}\n\n")
        f.write(f"Stable Diffusion Prompt:\n{sd_prompt}\n")
        if art_path:
            f.write(f"\nGenerated Image Location: {art_path}")
    
    print(f"Results saved to: {output_path}")
    
    # Optional: Also append to summary log file
    log_path = os.path.join(OUTPUT_DIR, "ai_art_history.log")
    with open(log_path, "a", encoding='utf-8') as log:
        log.write(f"\n\n=== Generation Record {timestamp} ===\n")
        log.write(f"Prompt: {sd_prompt[:200]}...\n")  # Truncate partial content

if __name__ == "__main__":
    init_resources()
    add_word_to_bank() 
    try:
        # 1. Capture and describe image
        image_path = capture_image()
        caption = generate_blip_prompt(image_path)
        print(f"Image Caption: {caption}")
        
        # 2. Generate poetry
        keywords = get_semantic_words(caption, word_bank, k=4)
        print(f"Semantically Matched Keywords: {keywords}")
        poem = generate_with_ollama(OLLAMA_MODEL, compose_poetry_instruction(caption, keywords))
        print(f"\nPoem:\n{poem}")
        
        # 3. Convert to prompt
        sd_prompt = poem_to_diffusion_prompt(poem)
        print(f"\nPrompt:\n{sd_prompt}")
        
        # 4. Generate image using Stable Diffusion
        art_path = generate_sd_image(sd_prompt)
        
        # 5. Save results
        save_results(image_path, caption, keywords, poem, sd_prompt, art_path)
        print(f"\nResults saved to {OUTPUT_DIR}")
        
    except Exception as e:
        print(f"Error: {e}")